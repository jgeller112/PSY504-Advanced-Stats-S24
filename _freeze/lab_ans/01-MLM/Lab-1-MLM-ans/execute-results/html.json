{
  "hash": "400805d3e3138a4a8d203d828f2c3c2e",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Lab 1 - Multilevel Models - Ans\"\noutput: \n  tufte::tufte_html:\n    css: \n    tufte_variant: \"envisioned\"\n    highlight: github-dark\n    fig_height: 10\n    toc: true\n    toc_depth: 1\nexecute: \n  message: false\n  warning: false\nformat: \n  html:\n    code-fold: true\n    code-overflow: wrap\nengine: knitr\n---\n\n\n# Lab 1: MLM\n\nToday's lab uses data from a study conducted by Coyne et al. (2019), which examined the impact of a high-quality, evidence-based vocabulary instruction intervention in kindergarten. The data consists of 1,428 students who were nested in 233 clusters or classrooms (`clu_id`).\n\nIn the sample of at-risk youth in the classroom (*N* = 6), half were allocated to treatment and the other half to control. The treatment group received supplemental small-group vocabulary instruction in addition to the whole-group instruction, while the control group received only whole-group vocabulary instruction. Since the observations were not independent (due to students being nested within classrooms), the researchers needed to account for this in their analysis.\n\nThe main question that the researchers aimed to answer was whether the supplemental small-group kindergarten vocabulary instruction intervention increased students' knowledge of the vocabulary words taught in the intervention. To measure vocabulary knowledge, the researchers used an ETW (ETW_SpringK) assessment, which evaluated students' ability to explain the meaning of a given word. The assessment was administered after the intervention concluded, in the spring of kindergarten. In the sample, ETW scores ranged from 0 to 52 (the maximum score), with a mean of 13.65 and a standard deviation of 11.10. To answer the research question, the researchers used two fixed effects and their interaction: `TRT` (1 = treatment and 0 = control) and PPVT (Peabody Picture Vocabulary Test, which measures students' vocabulary before the intervention; `PPVT_FallK`).\n\n> Coyne, M. D., McCoach, D. B., Ware, S., Austin, C. R., Loftus-Rattan, S. M., & Baker, D. L. (2019). Racing Against the Vocabulary Gap: Matthew Effects in Early Vocabulary Instruction and Intervention. *Exceptional Children*, *85*(2), 163--179. <https://doi.org/10.1177/0014402918789162>\n\n## Load packages\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# fill in packages you need as you go here\n# fill in packages you need as you go here\nlibrary(tidyverse) # data wrangling\nlibrary(knitr) # nice tables\nlibrary(patchwork) # combine figures\nlibrary(lme4) # fit mixed models\nlibrary(lmerTest) # mixed models\nlibrary(broom.mixed) # tidy output of mixed models\nlibrary(afex) # fit mixed models for lrt test\nlibrary(emmeans) # marginal means\nlibrary(ggeffects) # marginal means\nlibrary(ggrain) # rain plots\nlibrary(easystats) # nice ecosystem of packages\nlibrary(interactions)\n```\n:::\n\n\n## Load data\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# read in data file \ndata <- read.csv(\"Ch3_MLM_R.csv\")\n```\n:::\n\n\n# Lab 1\n\n## Data structure\n\n1.  What are the Level 1 and Level 2 variables in this study? How many units are in Level 1? Level 2? Are the fixed effects at Level 1 or Level 2?\n1.  What are the Level 1 and Level 2 variables in this study? How many units are in Level 1? Level 2? Are the fixed effects at Level 1 or Level 2?\n\n* Level 1 variables: `ETW_SpringK`, `TRT`, and `PPVT_FallK`.\n\n* There are 1,427 units in Level 1. There are 222 units in Level 2. \n\n* The fixed effects are at Level 1 because they pertain to the individual student-level variables and their interactions.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Assuming 'data' is your dataframe and 'clu_id' identifies the clusters/classrooms\nsummary_stats <- data %>%\n  group_by(clu_id) %>%\n  summarise(N_students = n()) %>%\n  ungroup() %>%\n  summarise(\n    N_clusters = n(),\n    Total_students = sum(N_students),\n    Average_students_per_classroom = mean(N_students),\n    SD_students_per_classroom = sd(N_students),\n    Min_students_in_classroom = min(N_students),\n    Max_students_in_classroom = max(N_students)\n  )\n\n# Extracting the values to variables for easier printing\nn_clusters <- summary_stats$N_clusters\ntotal_students <- summary_stats$Total_students\naverage_students <- summary_stats$Average_students_per_classroom\nsd_students <- summary_stats$SD_students_per_classroom\nmin_students <- summary_stats$Min_students_in_classroom\nmax_students <- summary_stats$Max_students_in_classroom\n\n# Printing the summary using cat()\ncat(\"Dataset Statistics:\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nDataset Statistics:\n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Number of clusters (classrooms):\", n_clusters, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNumber of clusters (classrooms): 222 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Total number of students:\", total_students, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTotal number of students: 1427 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Average number of students per classroom:\", round(average_students, 1), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAverage number of students per classroom: 6.4 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Standard deviation of students per classroom:\", round(sd_students, 1), \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nStandard deviation of students per classroom: 2.2 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Minimum number of students in a classroom:\", min_students, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMinimum number of students in a classroom: 2 \n```\n\n\n:::\n\n```{.r .cell-code}\ncat(\"Maximum number of students in a classroom:\", max_students, \"\\n\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMaximum number of students in a classroom: 18 \n```\n\n\n:::\n:::\n\n\n2.  Deviation code (0.5, -0.5) the treatment variable\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#deviation code the TRT var\n\n#deviation code the TRT var\ndata <- data %>%\n  mutate(TRT = ifelse(TRT == 1, 0.5, -0.5))\n```\n:::\n\n\n3.  Group mean center **`PPVT_Fallk`**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#within-clustering centering\ndata <- data  %>%\nmutate(datawizard::demean(data, select=c(\"PPVT_FallK\"), group =\"clu_id\"))\n```\n:::\n\n\n4.  Create two nicely looking visualizations: One for the relationship between PPTV and EWR and one for the relationship between TRT and EWR. Make sure you plot the between-cluster (class) variability when you graph these (given how many clusters there are, randomly sample 20 of them to plot).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# fig 1\n\n# Randomly sample 20 clusters to plot\nset.seed(500) # for reproducibility\nclusters_sample <- data %>% \n  distinct(clu_id) %>%\n  mutate(clu_id = as.character(clu_id)) %>%\n  sample_n(20) %>%\n  pull(clu_id)\n\ndata_sample <- data %>% \n  filter(clu_id %in% clusters_sample)\n\nggplot(data_sample, aes(x = PPVT_FallK, y = ETW_SpringK, group = clu_id)) +\n  geom_point(aes(color = as.factor(clu_id))) +\n  geom_smooth(method = \"lm\", se = FALSE, aes(group = clu_id, color = as.factor(clu_id))) +\n  theme_minimal() +\n  theme(legend.position = \"none\") +\n  labs(title = \"PPTV scores vs EWR scores by classroom\", x = \"PPTV scores\", y = \"EWR scores\")\n```\n\n::: {.cell-output-display}\n![](Lab-1-MLM-ans_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# fig 2\n# bubble plots\n\n# PPVT_FallK and ETW_SpringK\np1_df <- data  %>%\n  group_by(clu_id) %>%\n  summarise(\n    mean_PPVT_FallK = mean(PPVT_FallK, na.rm = TRUE),\n    mean_ETW_SpringK = mean(ETW_SpringK, na.rm = TRUE),\n    n_students = n())\n\np1 = ggplot(p1_df, aes(x = mean_PPVT_FallK, y = mean_ETW_SpringK, size = n_students)) +\n  geom_point(alpha = .5, color = \"#6096ba\") +\n  scale_size_continuous(range = c(1, 12), guide = \"none\") +\n  labs(title = \"Peabody Picture Vocabulary Test (PPVT) Scores by\\nExpressive Target Word Measure (ETW) Scores\",\n       x = \"Mean PPVT\",\n       y = \"Mean ETW\") +\n  theme_classic() +\n  theme(\n    axis.title = element_text(size = 14),\n    axis.text = element_text(size = 12)\n  )\n  \n# ETW_SpringK and TVT  \n  p2_df = data  %>%\ngroup_by(clu_id, TRT) %>%\nsummarise(mean_ETW_SpringK = mean(ETW_SpringK, na.rm = TRUE),\nn_students = n())\n\n  p2 = ggplot(p2_df, aes(x = factor(TRT), y = mean_ETW_SpringK)) +\nggdist::stat_halfeye(\n  adjust = .5,\n  width = .4,\n  .width = 0,\n  justification = -.9,\n  point_colour = NA,\n  fill = \"#6096ba\"\n) +\ngeom_point(aes(group = factor(clu_id), size = n_students), position = position_dodge(width = .5), alpha = .5, color = \"#6096ba\") +\nguides(size = \"none\") +\nlabs(title = \"Expressive Target Word Measure (ETW) Scores\\nby Condition\",\n     x = \"Condition\",\n     y = \"\") +\nscale_x_discrete(labels = c(\"Control\", \"Treatment\")) +\ntheme_classic() +\ntheme(\n  axis.title = element_text(size = 14),\n  axis.text = element_text(size = 12)\n  )\n  \ncombined_plot = p1 | p2\n  \n  caption_text = \"Figure 1.\\nA: Mean classroom scores on the PPVT and ETW. Each 'bubble' represents a cluster or classroom. Larger bubbles represent classes with more students.\\nB: ETW scores by experimental condition. Each bubble represents the average ETW score for a classroom-condition pair.\\nLarger bubbles represent pairs containing more students.\"\n  \n  annotated_plot = combined_plot &\nplot_annotation(\n  tag_levels = \"A\",\n  caption = caption_text,\n  theme = theme(\n    plot.caption = element_text(size = 12, hjust = 0)\n  )\n)\n  \n  annotated_plot\n```\n\n::: {.cell-output-display}\n![](Lab-1-MLM-ans_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n\n```\n\n## Model comparisons\n\n5.  Fit an unconditional means (null model)\n\n::: callout-tip\nmake sure you load `lmerTest` to get *p*-values\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel1 <- lmer(ETW_SpringK ~ 1 + (1|clu_id), \n                data = data, REML=TRUE)\n\nsummary(model1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: ETW_SpringK ~ 1 + (1 | clu_id)\n   Data: data\n\nREML criterion at convergence: 10855.9\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-1.8972 -0.6979 -0.2156  0.5325  3.5095 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n clu_id   (Intercept)  19.91    4.462  \n Residual             104.43   10.219  \nNumber of obs: 1427, groups:  clu_id, 222\n\nFixed effects:\n            Estimate Std. Error       df t value Pr(>|t|)    \n(Intercept)  13.7248     0.4094 201.4834   33.52   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n> What is the ICC? Calculate it by hand from the output.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Extract the variance components from the model output\ncluster_variance <- 19.91\nresidual_variance <-  104.43\n\n# Calculate ICC\nicc <- cluster_variance / (cluster_variance + residual_variance)\n\nround(icc, 4)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.1601\n```\n\n\n:::\n:::\n\n\n> Use the `icc` function in `easystats` to calculate the icc\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#easystats\nperformance::icc(model1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Intraclass Correlation Coefficient\n\n    Adjusted ICC: 0.160\n  Unadjusted ICC: 0.160\n```\n\n\n:::\n:::\n\n\n> Is multilevel modeling warranted here?\n  > Yep!\n> What does the ICC mean?\n  > It tells us how much variability there is between clusters. It also tells how how correlated our level 1 units are to one another. In this case, we have observe an ICC of 0.160, which indicates that 16% of the total variance in our outcome variable (students' vocabulary knowledge scores`ETW_SpringK`) is attributable to differences between classroom (Level 2 variance). \n\n6.  Build up from the last model. Fit a model that includes all level 1 variables (no interaction)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlevel_1_model <- lmer(ETW_SpringK ~ TRT + PPVT_FallK + (1|clu_id), data = data)\n\nsummary(level_1_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: ETW_SpringK ~ TRT + PPVT_FallK + (1 | clu_id)\n   Data: data\n\nREML criterion at convergence: 10349.1\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.4814 -0.6259 -0.1126  0.5149  3.9787 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n clu_id   (Intercept) 21.60    4.647   \n Residual             69.93    8.362   \nNumber of obs: 1427, groups:  clu_id, 222\n\nFixed effects:\n              Estimate Std. Error         df t value Pr(>|t|)    \n(Intercept)  -25.36477    3.95423 1398.06475  -6.415 1.93e-10 ***\nTRT           10.44860    0.45197 1250.92144  23.118  < 2e-16 ***\nPPVT_FallK     0.46073    0.04665 1386.53447   9.876  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n           (Intr) TRT   \nTRT        -0.022       \nPPVT_FallK -0.995  0.020\n```\n\n\n:::\n:::\n\n\n7.  Fit a model that includes the fixed interaction between the level-1 variables\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninteraction_model <- lmer(ETW_SpringK ~ TRT * PPVT_FallK + (1|clu_id), data = data)\nsummary(interaction_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: ETW_SpringK ~ TRT * PPVT_FallK + (1 | clu_id)\n   Data: data\n\nREML criterion at convergence: 10339.1\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.6149 -0.6202 -0.1202  0.5219  4.1549 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n clu_id   (Intercept) 21.66    4.655   \n Residual             69.25    8.322   \nNumber of obs: 1427, groups:  clu_id, 222\n\nFixed effects:\n                 Estimate Std. Error         df t value Pr(>|t|)    \n(Intercept)     -25.30463    3.93672 1396.23692  -6.428 1.77e-10 ***\nTRT             -16.10042    7.33721 1244.64815  -2.194   0.0284 *  \nPPVT_FallK        0.46021    0.04644 1384.47855   9.909  < 2e-16 ***\nTRT:PPVT_FallK    0.31512    0.08693 1245.16529   3.625   0.0003 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) TRT    PPVT_F\nTRT         -0.005              \nPPVT_FallK  -0.995  0.004       \nTRT:PPVT_FK  0.004 -0.998 -0.002\n```\n\n\n:::\n:::\n\n\n8.  Compare the main effects and interaction models. Which model is the best?\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntest_likelihoodratio(level_1_model, interaction_model, REML=FALSE) %>% kable()\n```\n\n::: {.cell-output-display}\n\n\n|    |Name |Model           | df| df_diff|     Chi2|         p|\n|:---|:----|:---------------|--:|-------:|--------:|---------:|\n|..1 |..1  |lmerModLmerTest |  5|      NA|       NA|        NA|\n|..2 |..2  |lmerModLmerTest |  6|       1| 13.10682| 0.0002942|\n\n\n:::\n:::\n\n\n- The interaction model is statistically superior to the main effects model, as indicated by lower AIC and BIC scores. This is further confirmed by a statistically significant likelihood ratio test ($\\chi^2 = 8.39$, $p = .0038$). This suggests that including the interaction between `TRT` and `PPVT_FallK` provides a better fit to the data. \n\n9.  Use the best model from above and fit a model that adds random slopes for `TRT`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbest_model <- lmer(ETW_SpringK ~ TRT * PPVT_FallK + (1+ TRT|clu_id), data = data)\n```\n:::\n\n\n10. Now create a model with a random slope for treatment and PPVT scores. This will be our maximal model.\n\n```         \n::: callout-warning\nWe could include a random slope for the interaction between the two, but we only have 6 students per classroom and makes our model too complex.\n:::\n```\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncomplex_model <- lmer(ETW_SpringK ~ TRT * PPVT_FallK + (1 + TRT + PPVT_FallK|clu_id), data = data)\n```\n:::\n\n\n11. Compare the random slopes for `TRT` model to the the random slopes for treatment and `PPVT`model. Which one is better?\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntest_likelihoodratio(best_model, complex_model) %>%  kable()\n```\n\n::: {.cell-output-display}\n\n\n|              |Name          |Model           | df| df_diff|     Chi2|         p|\n|:-------------|:-------------|:---------------|--:|-------:|--------:|---------:|\n|best_model    |best_model    |lmerModLmerTest |  8|      NA|       NA|        NA|\n|complex_model |complex_model |lmerModLmerTest | 11|       3| 1.026711| 0.7947889|\n\n\n:::\n:::\n\n\n> Take a look at the maximal model output. What is the warning message?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nisSingular(complex_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] FALSE\n```\n\n\n:::\n:::\n\n\n> Why do you think we are getting that message? How can we get rid of the warning?\n\n- We observe that the more complex model has a singular fit, which likely results from overfitting the data. In particular, the more complex model contains random slopes for both `TRT` and `PPVT_FallK` within clusters (`clu_id`). We can infer that there is not enough variation in `TRT` or `PPVT_FallK` within clusters, so the model may not be able to estimate random effects reliably. To get rid of this warning, we could reduce complexity in the model by removing some of the random slopes. \n## Model interpretation\n\n12. What is the best model? \n\n- Model with random slopes for TRT and random intercepts for classroom\n\n13. Using the best model, examine the fixed effects. Please interpret these effects/coefs in a sentence or two. You can use whatever method you would like (e.g., t-tests or LRT). Follow these up with the appropriate tests (e.g., simple slopes analysis if interaction is significant).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# fit the best model and output a nice summary table of results. \n\nlibrary(afex) # load afex in \n\nm <- mixed(ETW_SpringK ~ TRT * PPVT_FallK + (1+ TRT|clu_id), data=data, method = \"LRT\") # fit lmer using afex\n\nnice(m) %>%\n  kable()\n```\n\n::: {.cell-output-display}\n\n\n|Effect         | df|Chisq      |p.value |\n|:--------------|--:|:----------|:-------|\n|TRT            |  1|3.15 +     |.076    |\n|PPVT_FallK     |  1|107.89 *** |<.001   |\n|TRT:PPVT_FallK |  1|10.74 **   |.001    |\n\n\n:::\n\n```{.r .cell-code}\nemtrends(best_model, ~TRT, var=\"PPVT_FallK\") %>%\n  test() %>%\n  kable()\n```\n\n::: {.cell-output-display}\n\n\n|  TRT| PPVT_FallK.trend|        SE|       df|  t.ratio| p.value|\n|----:|----------------:|---------:|--------:|--------:|-------:|\n| -0.5|        0.3120067| 0.0565135| 1180.010| 5.520926|       0|\n|  0.5|        0.5827390| 0.0617509| 1167.729| 9.436926|       0|\n\n\n:::\n:::\n\n\n14. Evaluate the variance components of your model. Explain what each means\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_parameters(best_model, effects=\"random\") %>% kable()\n```\n\n::: {.cell-output-display}\n\n\n|Parameter           | Coefficient|SE |   CI|CI_low |CI_high |Effects |Group    |\n|:-------------------|-----------:|:--|----:|:------|:-------|:-------|:--------|\n|SD (Intercept)      |   4.7798625|NA | 0.95|NA     |NA      |random  |clu_id   |\n|SD (TRT)            |   6.6910483|NA | 0.95|NA     |NA      |random  |clu_id   |\n|Cor (Intercept~TRT) |   0.8922365|NA | 0.95|NA     |NA      |random  |clu_id   |\n|SD (Observations)   |   7.5474782|NA | 0.95|NA     |NA      |random  |Residual |\n\n\n:::\n:::\n\n\n- The variance is  25.01 for the intercepts across the different classrooms (`clu_id`). This suggests there is substantial variability in the baseline `ETW_SpringK` scores that can be attributed to differences between classrooms before considering `TRT` or `PPVT_FallK` scores. \n- The variance associated with the treatment effect (`TRT`) across classrooms is 45.51. This suggests significant variability in how the treatment effect on `ETW_SpringK` scores differs from one classroom to another.\n- The variance of residuals is 57.02. This indicates the remaining within-classroom variance in student scores that cannot be explained by the model's fixed effects or the classroom-level random effects. \n- Overall, our  variance components are significant for both the random intercept and slope for `TRT`. This suggests that multilevel modeling is, indeed, appropriate and necessary to account for the clustering of student scores within classrooms and the variability in treatment effects across classrooms.\n\n\n## Model fit\n\n15. Calculate the conditional and marginal pseudo-$R^2$ of the model\n\n\n::: {.cell}\n\n```{.r .cell-code}\nr2(best_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# R2 for Mixed Models\n\n  Conditional R2: 0.543\n     Marginal R2: 0.262\n```\n\n\n:::\n:::\n\n\n16. Calculate the semi-$R^2$ for the `PPVT` variable using the `partR2` function from `partR2` package\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(partR2)\npartR2(best_model, data = data, partvars = c(\"PPVT_FallK\"), R2_type = \"marginal\", nboot = 10, CI = 0.95)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\nR2 (marginal) and 95% CI for the full model: \n R2     CI_lower CI_upper nboot ndf\n 0.2619 0.2324   0.3103   10    4  \n\n----------\n\nPart (semi-partial) R2:\n Predictor(s) R2     CI_lower CI_upper nboot ndf\n Model        0.2619 0.2324   0.3103   10    4  \n PPVT_FallK   0.0446 0.0068   0.1114   10    3  \n```\n\n\n:::\n:::\n\n\n17. Calculate Cohen's $d$ for the treatment effect\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd = 10.44 / 11.44 # sigma is sqrt of all variance (intercept + slopes + residual)\n```\n:::\n\n\n18. Visualize the random intercepts and slopes in your model\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrandom <- estimate_grouplevel(best_model)\nplot(random) + theme_lucid()\n```\n\n::: {.cell-output-display}\n![](Lab-1-MLM-ans_files/figure-html/unnamed-chunk-23-1.png){width=768}\n:::\n:::\n\n\n## Assumptions\n\n19. Check model assumptions with `check_model`. Do any of the assumptions appear to be violated?\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_model(best_model)\n```\n\n::: {.cell-output-display}\n![](Lab-1-MLM-ans_files/figure-html/unnamed-chunk-24-1.png){width=768}\n:::\n:::\n\n\n- Some outliers\n- Level 1 residuals looks skewed \n## Table\n\n20. Create a table with a summary of your model information\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodelsummary::modelsummary(best_model)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:center;\">  (1) </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> (Intercept) </td>\n   <td style=\"text-align:center;\"> −24.259 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:center;\"> (3.584) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> TRT </td>\n   <td style=\"text-align:center;\"> −12.381 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:center;\"> (6.981) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> PPVT_FallK </td>\n   <td style=\"text-align:center;\"> 0.447 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:center;\"> (0.042) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> TRT × PPVT_FallK </td>\n   <td style=\"text-align:center;\"> 0.271 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:center;\"> (0.083) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> SD (Intercept clu_id) </td>\n   <td style=\"text-align:center;\"> 4.780 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> SD (TRT clu_id) </td>\n   <td style=\"text-align:center;\"> 6.691 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Cor (Intercept~TRT clu_id) </td>\n   <td style=\"text-align:center;\"> 0.892 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;box-shadow: 0px 1px\"> SD (Observations) </td>\n   <td style=\"text-align:center;box-shadow: 0px 1px\"> 7.547 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Num.Obs. </td>\n   <td style=\"text-align:center;\"> 1427 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> R2 Marg. </td>\n   <td style=\"text-align:center;\"> 0.262 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> R2 Cond. </td>\n   <td style=\"text-align:center;\"> 0.543 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> AIC </td>\n   <td style=\"text-align:center;\"> 10210.1 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> BIC </td>\n   <td style=\"text-align:center;\"> 10252.2 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> ICC </td>\n   <td style=\"text-align:center;\"> 0.4 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> RMSE </td>\n   <td style=\"text-align:center;\"> 6.98 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n## Visualization\n\n21. Visualize the interaction between `TRT` and `PPVT` score on ETW (I would check out the `interactions` or `ggeffects` packages. They have some nice features for plotting interactions.)\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninteract_plot(best_model, pred = \"PPVT_FallK\", modx = \"TRT\", data = data)\n```\n\n::: {.cell-output-display}\n![](Lab-1-MLM-ans_files/figure-html/unnamed-chunk-26-1.png){width=672}\n:::\n:::\n\n\n## Reporting Results\n\n22. Write-up the results of your MLM model incorporating the above information. This write-up should resemble what you would find in a published paper. You can use the textbook for guidance and the `report` function from `easystats`\n\nThe present study investigated the impact of a vocabulary instruction intervention on students' knowledge, using a nested data structure with two levels: students (Level 1) nested within classrooms (Level 2). The analysis included 1,427 students distributed across 222 classrooms. Classrooms varied in size, with an average of approximately 6.4 students per classroom ($SD = 2.2$, $range = [2, 18]$). \n\nThe relationship between the intervention and vocabulary knowledge was modeled using a multilevel linear model, represented by the following equation:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nequatiomatic::extract_eq(best_model)\n```\n\n::: {.cell-output-display}\n$$\n\\begin{aligned}\n  \\operatorname{ETW\\_SpringK}_{i}  &\\sim N \\left(\\mu, \\sigma^2 \\right) \\\\\n    \\mu &=\\alpha_{j[i]} + \\beta_{1j[i]}(\\operatorname{TRT}) + \\beta_{2}(\\operatorname{PPVT\\_FallK}) + \\beta_{3}(\\operatorname{PPVT\\_FallK} \\times \\operatorname{TRT}) \\\\    \n\\left(\n  \\begin{array}{c} \n    \\begin{aligned}\n      &\\alpha_{j} \\\\\n      &\\beta_{1j}\n    \\end{aligned}\n  \\end{array}\n\\right)\n  &\\sim N \\left(\n\\left(\n  \\begin{array}{c} \n    \\begin{aligned}\n      &\\mu_{\\alpha_{j}} \\\\\n      &\\mu_{\\beta_{1j}}\n    \\end{aligned}\n  \\end{array}\n\\right)\n, \n\\left(\n  \\begin{array}{cc}\n     \\sigma^2_{\\alpha_{j}} & \\rho_{\\alpha_{j}\\beta_{1j}} \\\\ \n     \\rho_{\\beta_{1j}\\alpha_{j}} & \\sigma^2_{\\beta_{1j}}\n  \\end{array}\n\\right)\n \\right)\n    \\text{, for clu\\_id j = 1,} \\dots \\text{,J}\n\\end{aligned}\n$$\n\n:::\n:::\n\n\nwhere $ETW\\_SpringK$ is the student's score on the vocabulary knowledge assessment, $TRT$ is the treatment condition, $PPVT\\_FallK$ is the Peabody Picture Vocabulary Test score, and $(1 + TRT | clu\\_id)$ represents the random intercepts and slopes for treatment across classrooms. Note that $ETW\\_SpringK$, $TRT$, and $PPVT\\_FallK$ are all Level 1 variables, and $clu\\_id$ is at Level 2. For the above analysis, we mean centered $PPVT\\_FallK$ within each cluster and deviation coded $TRT$. \n\nBefore settling on the above model, we estimated an unconditional means (null) model and maximal model, which included a random slope for both treatment and PPVT scores. We compared the above model ($df = 8$) to the maximal model ($df = 11$) using a likelihood ratio test from the `easystats` package (version 0.6.0). We found that the more complex model did not significantly improve model fit ($\\chi^2 = 4.85$, $p = 0.185$). We therefore proceeded to use the simpler model for our analyses, as there was not sufficient evidence to justify additional complexity in our model. \n\nWe checked our model assumptions (linearity, normality of residuals, homoscedasticity, collinearity) visually, using diagnostic plots from the `performance` package (version 0.10.5). Based on this visual assessment, we found that all our model assumptions were satisfied. The Intraclass Correlation Coefficient (ICC) for the outcome variable was calculated as 0.16, suggesting that 16% of the variance in vocabulary knowledge scores could be attributed to differences between classrooms. The models were estimated using Restricted Maximum Likelihood (REML) to account for the nested data structure. The `lme4` package (version 1.1.34) was used for fitting the model, with the `interactions` package (version 1.1.5) for estimating and plotting interactions.\n\nThe fixed effects analysis revealed a significant intercept ($b = 13.47$, $SE = 0.40$, $t(209) = 34.03$, $p < .001$), indicating a high baseline level of vocabulary knowledge. The treatment effect was also significant ($b = 10.47$, $SE = 0.62$, $t(213) = 17.02$, $p < .001$), suggesting that the treatment had a substantial positive impact on vocabulary knowledge. Additionally, PPVT scores were positively associated with ETW scores ($b = 0.43$, $SE = 0.04$, $t(1091) = 9.67$, $p < .001$), indicating that higher initial vocabulary levels were associated with higher post-intervention vocabulary knowledge. The interaction between treatment and PPVT scores was also significant ($b = 0.28$, $SE = 0.09$, $t(1074) = 3.06$, $p = .002$), suggesting that the treatment effect varied as a function of initial vocabulary levels.\n\nRegarding random effects, we observe a variance of 25.01 ($SD = 5.00$) for the intercepts across the different classrooms. This suggests there is substantial variability in the baseline ETW scores that can be attributed to differences between classrooms before considering treatment or PPVT scores. The variance associated with the treatment effect across classrooms was 45.51 ($SD = 6.75$). This suggests significant variability in how the treatment effect on  ETW scores differs from across clasrooms. Finally, the variance of residuals was 57.02 ($SD = 7.55$), indicating within-classroom variance in student scores that cannot be explained by the model's fixed effects or the classroom-level random effects. Overall, our  variance components are significant for both the random intercept and slope for treatment. This suggests that multilevel modeling is, indeed, appropriate and necessary to account for the clustering of student scores within classrooms and the variability in treatment effects across classrooms.\n\nthe model estimated the standard deviation of the random intercepts for classrooms ($SD = 5.00$), indicating variability in baseline ETW scores across classrooms. The correlation between the random intercepts and slopes for treatment within classrooms was estimated to be 0.89, suggesting a strong positive relationship between the classroom baseline scores and the treatment effect. The standard deviation of the random slopes for treatment ($SD = 6.75$) indicated substantial variability in the treatment effect across classrooms. The residual standard deviation ($SD = 7.55$) reflected the within-classroom variability in ETW scores that was not explained by the model's fixed and random effects.\n\nTaken together, these results suggest that both the treatment and initial PPVT scores are significant predictors of students' vocabulary knowledge. There was a notable interaction effect, suggesting that the benefit of the treatment varies depending on students' initial vocabulary levels. The significant random effects for treatment across classrooms underscore the intervention's differential effectiveness depending on classroom context. These findings highlight the importance of considering both the individual and contextual factors in educational interventions.\n",
    "supporting": [
      "Lab-1-MLM-ans_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}